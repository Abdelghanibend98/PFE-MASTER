{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd8935d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "\n",
    "with open('DATASET.npy', 'rb') as f:\n",
    "    targets = np.load(f)\n",
    "    notes = np.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "315f1b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((notes[0:99], targets[0:99]))\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((notes[100:131], targets[100:131]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6935d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modele(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Modele, self).__init__()\n",
    "        self.conv_layer_one = tf.keras.layers.Conv1D(11, kernel_size=1, strides=1, activation='relu', padding='same', name='conv_layer_one')\n",
    "        self.conv_layer_two = tf.keras.layers.Conv1D(11, kernel_size=3, strides=3, activation='relu', padding='same', name='conv_layer_two')\n",
    "        self.flatten_layer = tf.keras.layers.Flatten(name='flatten_layer')\n",
    "        self.input_layer = tf.keras.layers.Dense(11, activation='relu', name='input_layer')\n",
    "        self.output_layer = tf.keras.layers.Dense(2, activation='softmax', name='output_layer')\n",
    "\n",
    "    def call(self, notes):\n",
    "        conv_layer_one = self.conv_layer_one(notes)\n",
    "        conv_layer_two = self.conv_layer_two(conv_layer_one)\n",
    "        flatten_layer = self.flatten_layer(conv_layer_two)\n",
    "        input_layer = self.input_layer(flatten_layer)\n",
    "        output_layer = self.output_layer(input_layer)\n",
    "        return output_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c085df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Modele()\n",
    "# model.compile(\n",
    "#     loss=\"sparse_categorical_crossentropy\",\n",
    "#     optimizer=\"sgd\",\n",
    "#     metrics=[\"accuracy\"]\n",
    "# )\n",
    "# model.fit(notes[20:120], targets[20:120], epochs=5)\n",
    "# model.save(\"model_test\", save_format=\"tf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41eea69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54901cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss \"L'erreur\"\n",
    "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "valid_loss = tf.keras.metrics.Mean(name=\"valid_loss\")\n",
    "# Accuracy \"La précision\"\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"train_accuracy\")\n",
    "valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"test_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fa898f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(note, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # faire une prediction sur tous le batch (groupe ou patie)\n",
    "        prediction = model(note, training=True)\n",
    "        # calculer l'erreur sur cette prediction\n",
    "        loss = loss_object(target, prediction)\n",
    "    # calcule le gradient qui respecte l'erreur  \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    # optimiser les poids du model selon le gradient calculé\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_accuracy(target, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29f0ba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(note, target):\n",
    "    # faire une prediction sur tous le batch (groupe ou patie)\n",
    "    prediction = model(note)\n",
    "    # calculer l'erreur sur cette prediction\n",
    "    loss = loss_object(target, prediction)\n",
    "    valid_loss(loss)\n",
    "    valid_accuracy(target, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07991158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch: 0/132, erreur:  1.3748784065246582, Précision: 60.000003814697266\n",
      " batch: 10/132, erreur:  1.2804428339004517, Précision: 55.0\n",
      " batch: 20/132, erreur:  1.1457446813583374, Précision: 56.66666793823242\n",
      " batch: 30/132, erreur:  1.08902108669281, Précision: 60.000003814697266\n",
      " batch: 40/132, erreur:  1.0714702606201172, Précision: 58.0\n",
      " batch: 50/132, erreur:  0.9613497257232666, Précision: 63.33333206176758\n",
      " batch: 60/132, erreur:  0.8494951128959656, Précision: 68.5714340209961\n",
      " batch: 70/132, erreur:  0.8062482476234436, Précision: 70.0\n",
      " batch: 80/132, erreur:  0.8139694929122925, Précision: 68.8888931274414\n",
      " batch: 90/132, erreur:  0.824445366859436, Précision: 66.66667175292969\n",
      " epoch: 1, Test erreur:  0.45134982466697693, Test Précision: 80.0\n",
      " epoch: 1, Test erreur:  0.6358479857444763, Test Précision: 65.0\n",
      " epoch: 1, Test erreur:  0.5868467092514038, Test Précision: 66.66667175292969\n",
      " epoch: 1, Test erreur:  0.9381057024002075, Test Précision: 64.51612854003906\n",
      "------------\n",
      " batch: 100/132, erreur:  0.9426566958427429, Précision: 60.000003814697266\n",
      " batch: 110/132, erreur:  0.9116137027740479, Précision: 55.0\n",
      " batch: 120/132, erreur:  0.8404500484466553, Précision: 56.66666793823242\n",
      " batch: 130/132, erreur:  0.8177980184555054, Précision: 60.000003814697266\n",
      " batch: 140/132, erreur:  0.7929962277412415, Précision: 58.0\n",
      " batch: 150/132, erreur:  0.7452940344810486, Précision: 61.66666793823242\n",
      " batch: 160/132, erreur:  0.6837115287780762, Précision: 67.14285278320312\n",
      " batch: 170/132, erreur:  0.6665650010108948, Précision: 68.75\n",
      " batch: 180/132, erreur:  0.6811492443084717, Précision: 66.66667175292969\n",
      " batch: 190/132, erreur:  0.6930715441703796, Précision: 65.65657043457031\n",
      " epoch: 2, Test erreur:  0.5057967901229858, Test Précision: 80.0\n",
      " epoch: 2, Test erreur:  0.6013891696929932, Test Précision: 60.000003814697266\n",
      " epoch: 2, Test erreur:  0.5599539875984192, Test Précision: 70.0\n",
      " epoch: 2, Test erreur:  0.7652930021286011, Test Précision: 67.74193572998047\n",
      "------------\n",
      " batch: 200/132, erreur:  0.7920496463775635, Précision: 60.000003814697266\n",
      " batch: 210/132, erreur:  0.7924709916114807, Précision: 60.000003814697266\n",
      " batch: 220/132, erreur:  0.748223066329956, Précision: 60.000003814697266\n",
      " batch: 230/132, erreur:  0.7310088276863098, Précision: 60.000003814697266\n",
      " batch: 240/132, erreur:  0.7133728861808777, Précision: 58.0\n",
      " batch: 250/132, erreur:  0.6906887888908386, Précision: 60.000003814697266\n",
      " batch: 260/132, erreur:  0.649206280708313, Précision: 65.71428680419922\n",
      " batch: 270/132, erreur:  0.6412739753723145, Précision: 67.5\n",
      " batch: 280/132, erreur:  0.655738890171051, Précision: 64.44444274902344\n",
      " batch: 290/132, erreur:  0.6659841537475586, Précision: 62.626258850097656\n",
      " epoch: 3, Test erreur:  0.5427865982055664, Test Précision: 80.0\n",
      " epoch: 3, Test erreur:  0.6064795255661011, Test Précision: 70.0\n",
      " epoch: 3, Test erreur:  0.5736907124519348, Test Précision: 76.66666412353516\n",
      " epoch: 3, Test erreur:  0.724693775177002, Test Précision: 74.19355010986328\n",
      "------------\n",
      " batch: 300/132, erreur:  0.7454626560211182, Précision: 60.000003814697266\n",
      " batch: 310/132, erreur:  0.7588836550712585, Précision: 55.0\n",
      " batch: 320/132, erreur:  0.7247564196586609, Précision: 56.66666793823242\n",
      " batch: 330/132, erreur:  0.7085156440734863, Précision: 57.5\n",
      " batch: 340/132, erreur:  0.6937268972396851, Précision: 56.0\n",
      " batch: 350/132, erreur:  0.6757426857948303, Précision: 58.33333206176758\n",
      " batch: 360/132, erreur:  0.6380521655082703, Précision: 64.28571319580078\n",
      " batch: 370/132, erreur:  0.6308403015136719, Précision: 66.25\n",
      " batch: 380/132, erreur:  0.6451051235198975, Précision: 63.33333206176758\n",
      " batch: 390/132, erreur:  0.6550600528717041, Précision: 62.626258850097656\n",
      " epoch: 4, Test erreur:  0.5351992845535278, Test Précision: 80.0\n",
      " epoch: 4, Test erreur:  0.602291464805603, Test Précision: 60.000003814697266\n",
      " epoch: 4, Test erreur:  0.5727352499961853, Test Précision: 66.66667175292969\n",
      " epoch: 4, Test erreur:  0.7216730117797852, Test Précision: 64.51612854003906\n",
      "------------\n",
      " batch: 400/132, erreur:  0.7459712028503418, Précision: 60.000003814697266\n",
      " batch: 410/132, erreur:  0.752748966217041, Précision: 55.0\n",
      " batch: 420/132, erreur:  0.7183896899223328, Précision: 56.66666793823242\n",
      " batch: 430/132, erreur:  0.7026258111000061, Précision: 57.5\n",
      " batch: 440/132, erreur:  0.6895128488540649, Précision: 56.0\n",
      " batch: 450/132, erreur:  0.6693038940429688, Précision: 60.000003814697266\n",
      " batch: 460/132, erreur:  0.6302345991134644, Précision: 65.71428680419922\n",
      " batch: 470/132, erreur:  0.6216854453086853, Précision: 67.5\n",
      " batch: 480/132, erreur:  0.6364639401435852, Précision: 64.44444274902344\n",
      " batch: 490/132, erreur:  0.6458540558815002, Précision: 63.6363639831543\n",
      " epoch: 5, Test erreur:  0.5219269394874573, Test Précision: 80.0\n",
      " epoch: 5, Test erreur:  0.5980993509292603, Test Précision: 60.000003814697266\n",
      " epoch: 5, Test erreur:  0.5699572563171387, Test Précision: 66.66667175292969\n",
      " epoch: 5, Test erreur:  0.7222442626953125, Test Précision: 64.51612854003906\n",
      "------------\n",
      " batch: 500/132, erreur:  0.7592393755912781, Précision: 60.000003814697266\n",
      " batch: 510/132, erreur:  0.7551079988479614, Précision: 60.000003814697266\n",
      " batch: 520/132, erreur:  0.7184321284294128, Précision: 60.000003814697266\n",
      " batch: 530/132, erreur:  0.7007959485054016, Précision: 62.5\n",
      " batch: 540/132, erreur:  0.6888666749000549, Précision: 60.000003814697266\n",
      " batch: 550/132, erreur:  0.6666118502616882, Précision: 63.33333206176758\n",
      " batch: 560/132, erreur:  0.6260537505149841, Précision: 68.5714340209961\n",
      " batch: 570/132, erreur:  0.6163148283958435, Précision: 70.0\n",
      " batch: 580/132, erreur:  0.6312810778617859, Précision: 66.66667175292969\n",
      " batch: 590/132, erreur:  0.6399604082107544, Précision: 65.65657043457031\n",
      " epoch: 6, Test erreur:  0.5130906105041504, Test Précision: 80.0\n",
      " epoch: 6, Test erreur:  0.5940131545066833, Test Précision: 65.0\n",
      " epoch: 6, Test erreur:  0.5683536529541016, Test Précision: 66.66667175292969\n",
      " epoch: 6, Test erreur:  0.7186616659164429, Test Précision: 64.51612854003906\n",
      "------------\n",
      " batch: 600/132, erreur:  0.7631353139877319, Précision: 60.000003814697266\n",
      " batch: 610/132, erreur:  0.755576491355896, Précision: 55.0\n",
      " batch: 620/132, erreur:  0.7175140380859375, Précision: 56.66666793823242\n",
      " batch: 630/132, erreur:  0.6987981796264648, Précision: 60.000003814697266\n",
      " batch: 640/132, erreur:  0.6888502240180969, Précision: 58.0\n",
      " batch: 650/132, erreur:  0.6650886535644531, Précision: 61.66666793823242\n",
      " batch: 660/132, erreur:  0.6235474348068237, Précision: 67.14285278320312\n",
      " batch: 670/132, erreur:  0.6129224300384521, Précision: 68.75\n",
      " batch: 680/132, erreur:  0.6273308396339417, Précision: 65.55555725097656\n",
      " batch: 690/132, erreur:  0.6358401775360107, Précision: 64.6464614868164\n",
      " epoch: 7, Test erreur:  0.5086101293563843, Test Précision: 80.0\n",
      " epoch: 7, Test erreur:  0.5919588208198547, Test Précision: 65.0\n",
      " epoch: 7, Test erreur:  0.569746732711792, Test Précision: 66.66667175292969\n",
      " epoch: 7, Test erreur:  0.7136285901069641, Test Précision: 64.51612854003906\n",
      "------------\n",
      " batch: 700/132, erreur:  0.7557336688041687, Précision: 60.000003814697266\n",
      " batch: 710/132, erreur:  0.7513720393180847, Précision: 55.0\n",
      " batch: 720/132, erreur:  0.7148271203041077, Précision: 56.66666793823242\n",
      " batch: 730/132, erreur:  0.695652961730957, Précision: 60.000003814697266\n",
      " batch: 740/132, erreur:  0.687362551689148, Précision: 58.0\n",
      " batch: 750/132, erreur:  0.6631239056587219, Précision: 63.33333206176758\n",
      " batch: 760/132, erreur:  0.6209319829940796, Précision: 68.5714340209961\n",
      " batch: 770/132, erreur:  0.6093975901603699, Précision: 70.0\n",
      " batch: 780/132, erreur:  0.6241329908370972, Précision: 67.77777862548828\n",
      " batch: 790/132, erreur:  0.6326467394828796, Précision: 66.66667175292969\n",
      " epoch: 8, Test erreur:  0.5050343871116638, Test Précision: 80.0\n",
      " epoch: 8, Test erreur:  0.5901855230331421, Test Précision: 65.0\n",
      " epoch: 8, Test erreur:  0.5704879760742188, Test Précision: 66.66667175292969\n",
      " epoch: 8, Test erreur:  0.7103249430656433, Test Précision: 64.51612854003906\n",
      "------------\n",
      " batch: 800/132, erreur:  0.7510253190994263, Précision: 60.000003814697266\n",
      " batch: 810/132, erreur:  0.747085452079773, Précision: 55.0\n",
      " batch: 820/132, erreur:  0.7114312052726746, Précision: 56.66666793823242\n",
      " batch: 830/132, erreur:  0.6919440627098083, Précision: 60.000003814697266\n",
      " batch: 840/132, erreur:  0.6847766041755676, Précision: 58.0\n",
      " batch: 850/132, erreur:  0.6601815819740295, Précision: 63.33333206176758\n",
      " batch: 860/132, erreur:  0.6175450682640076, Précision: 68.5714340209961\n",
      " batch: 870/132, erreur:  0.6056304574012756, Précision: 70.0\n",
      " batch: 880/132, erreur:  0.6211508512496948, Précision: 67.77777862548828\n",
      " batch: 890/132, erreur:  0.6295773386955261, Précision: 65.65657043457031\n",
      " epoch: 9, Test erreur:  0.5028468370437622, Test Précision: 80.0\n",
      " epoch: 9, Test erreur:  0.5893577337265015, Test Précision: 65.0\n",
      " epoch: 9, Test erreur:  0.5716419816017151, Test Précision: 66.66667175292969\n",
      " epoch: 9, Test erreur:  0.7076135277748108, Test Précision: 64.51612854003906\n",
      "------------\n",
      " batch: 900/132, erreur:  0.7521609663963318, Précision: 60.000003814697266\n",
      " batch: 910/132, erreur:  0.7458088397979736, Précision: 55.0\n",
      " batch: 920/132, erreur:  0.7103260159492493, Précision: 56.66666793823242\n",
      " batch: 930/132, erreur:  0.6899206638336182, Précision: 60.000003814697266\n",
      " batch: 940/132, erreur:  0.6834226846694946, Précision: 58.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch: 950/132, erreur:  0.6588780283927917, Précision: 63.33333206176758\n",
      " batch: 960/132, erreur:  0.6164923906326294, Précision: 68.5714340209961\n",
      " batch: 970/132, erreur:  0.6043953895568848, Précision: 70.0\n",
      " batch: 980/132, erreur:  0.6195074319839478, Précision: 67.77777862548828\n",
      " batch: 990/132, erreur:  0.6273093223571777, Précision: 65.65657043457031\n",
      " epoch: 10, Test erreur:  0.5027255415916443, Test Précision: 80.0\n",
      " epoch: 10, Test erreur:  0.5880314111709595, Test Précision: 65.0\n",
      " epoch: 10, Test erreur:  0.573170006275177, Test Précision: 66.66667175292969\n",
      " epoch: 10, Test erreur:  0.7052252292633057, Test Précision: 64.51612854003906\n",
      "------------\n",
      "INFO:tensorflow:Assets written to: modele\\assets\n"
     ]
    }
   ],
   "source": [
    "epoch= 10\n",
    "batch_size = 10\n",
    "b =0\n",
    "model.compile(loss=loss_object, optimizer=optimizer)\n",
    "for epoch in range(epoch):\n",
    "    \n",
    "    for notes_batch, tagets_batch in train_dataset.batch(batch_size):\n",
    "        train_step(notes_batch, tagets_batch)\n",
    "        template = '\\r batch: {}/{}, erreur:  {}, Précision: {}'\n",
    "        print(template.format(b, len(targets), train_loss.result(), train_accuracy.result()*100))\n",
    "        b+= batch_size\n",
    "        \n",
    "        \n",
    "    for notes_batch, tagets_batch in valid_dataset.batch(batch_size):\n",
    "        test_step(notes_batch, tagets_batch)\n",
    "        template = '\\r epoch: {}, Test erreur:  {}, Test Précision: {}'\n",
    "        print(template.format(epoch+1, valid_loss.result(), valid_accuracy.result()*100))\n",
    "        \n",
    "    print(\"------------\")\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    valid_loss.reset_states()\n",
    "    valid_accuracy.reset_states()\n",
    "\n",
    "model.save(\"modele\", save_format=\"tf\")\n",
    "# tf.saved_model.save(model, \"saved_model_path\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f978eac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6078679 0.3921321]] [1]\n",
      "[[[11.   10.   10.    5.   15.5  10.25  7.    3.75  8.5  18.    7.  ]\n",
      "  [14.   12.   12.   13.   15.5  15.5  12.   12.5  15.5  18.   14.  ]\n",
      "  [11.   10.   11.    5.   15.5  10.25  7.   13.    8.5  18.    7.  ]]]\n"
     ]
    }
   ],
   "source": [
    "load_model = tf.keras.models.load_model(\"modele\")\n",
    "pred = load_model.predict(notes[100:101])\n",
    "print(pred, targets[100:101])\n",
    "print(notes[100:101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac5f9b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Aucun(e)",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
