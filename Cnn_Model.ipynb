{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd8935d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "\n",
    "# with open('DATASET.npy', 'rb') as f:\n",
    "#     targets = np.load(f)\n",
    "#     notes = np.load(f)\n",
    "with open('DATASET-MOY.npy', 'rb') as f:\n",
    "    targets = np.load(f)\n",
    "    notes = np.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "315f1b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((notes[0:250], targets[0:250]))\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((notes[251:350], targets[251:350]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6935d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modele(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Modele, self).__init__()\n",
    "        self.conv_layer_one = tf.keras.layers.Conv1D(11, kernel_size=1, strides=1, activation='relu', padding='same', name='conv_layer_one')\n",
    "        self.conv_layer_two = tf.keras.layers.Conv1D(11, kernel_size=3, strides=3, activation='relu', padding='same', name='conv_layer_two')\n",
    "        self.flatten_layer = tf.keras.layers.Flatten(name='flatten_layer')\n",
    "        self.input_layer = tf.keras.layers.Dense(11, activation='relu', name='input_layer')\n",
    "        self.output_layer = tf.keras.layers.Dense(2, activation='softmax', name='output_layer')\n",
    "\n",
    "    def call(self, notes):\n",
    "        conv_layer_one = self.conv_layer_one(notes)\n",
    "        conv_layer_two = self.conv_layer_two(conv_layer_one)\n",
    "        flatten_layer = self.flatten_layer(conv_layer_two)\n",
    "        input_layer = self.input_layer(flatten_layer)\n",
    "        output_layer = self.output_layer(input_layer)\n",
    "        return output_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c085df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Modele()\n",
    "# model.compile(\n",
    "#     loss=\"sparse_categorical_crossentropy\",\n",
    "#     optimizer=\"sgd\",\n",
    "#     metrics=[\"accuracy\"]\n",
    "# )\n",
    "# model.fit(notes[20:120], targets[20:120], epochs=5)\n",
    "# model.save(\"model_test\", save_format=\"tf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41eea69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54901cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss \"L'erreur\"\n",
    "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "valid_loss = tf.keras.metrics.Mean(name=\"valid_loss\")\n",
    "# Accuracy \"La précision\"\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"train_accuracy\")\n",
    "valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"test_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4fa898f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(note, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # faire une prediction sur tous le batch (groupe ou patie)\n",
    "        prediction = model(note, training=True)\n",
    "        # calculer l'erreur sur cette prediction\n",
    "        loss = loss_object(target, prediction)\n",
    "    # calcule le gradient qui respecte l'erreur  \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    # optimiser les poids du model selon le gradient calculé\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_accuracy(target, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29f0ba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(note, target):\n",
    "    # faire une prediction sur tous le batch (groupe ou patie)\n",
    "    prediction = model(note)\n",
    "    # calculer l'erreur sur cette prediction\n",
    "    loss = loss_object(target, prediction)\n",
    "    valid_loss(loss)\n",
    "    valid_accuracy(target, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07991158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch: 0/388, erreur:  5.21882438659668, Précision: 40.0\n",
      " batch: 10/388, erreur:  4.011632919311523, Précision: 50.0\n",
      " batch: 20/388, erreur:  3.091228485107422, Précision: 60.000003814697266\n",
      " batch: 30/388, erreur:  2.76322078704834, Précision: 62.5\n",
      " batch: 40/388, erreur:  2.5612101554870605, Précision: 64.0\n",
      " batch: 50/388, erreur:  2.223525285720825, Précision: 68.33333587646484\n",
      " batch: 60/388, erreur:  2.163465738296509, Précision: 67.14285278320312\n",
      " batch: 70/388, erreur:  1.9955203533172607, Précision: 68.75\n",
      " batch: 80/388, erreur:  2.0088348388671875, Précision: 67.77777862548828\n",
      " batch: 90/388, erreur:  2.0040650367736816, Précision: 66.0\n",
      " batch: 100/388, erreur:  1.9616512060165405, Précision: 65.45454406738281\n",
      " batch: 110/388, erreur:  1.9223304986953735, Précision: 65.0\n",
      " batch: 120/388, erreur:  1.9814484119415283, Précision: 63.846153259277344\n",
      " batch: 130/388, erreur:  2.0209338665008545, Précision: 61.42856979370117\n",
      " batch: 140/388, erreur:  1.9952479600906372, Précision: 60.000003814697266\n",
      " batch: 150/388, erreur:  1.9574662446975708, Précision: 58.749996185302734\n",
      " batch: 160/388, erreur:  1.8822355270385742, Précision: 58.82353210449219\n",
      " batch: 170/388, erreur:  1.832648754119873, Précision: 58.33333206176758\n",
      " batch: 180/388, erreur:  1.7560791969299316, Précision: 60.000003814697266\n",
      " batch: 190/388, erreur:  1.7108862400054932, Précision: 60.000003814697266\n",
      " batch: 200/388, erreur:  1.6970572471618652, Précision: 59.04762268066406\n",
      " batch: 210/388, erreur:  1.6398396492004395, Précision: 60.000003814697266\n",
      " batch: 220/388, erreur:  1.6317821741104126, Précision: 58.26087188720703\n",
      " batch: 230/388, erreur:  1.5897785425186157, Précision: 58.749996185302734\n",
      " batch: 240/388, erreur:  1.5572973489761353, Précision: 58.79999923706055\n",
      " epoch: 1, Test erreur:  1.103316068649292, Test Précision: 40.0\n",
      " epoch: 1, Test erreur:  0.8412504196166992, Test Précision: 55.0\n",
      " epoch: 1, Test erreur:  0.8331605792045593, Test Précision: 53.333335876464844\n",
      " epoch: 1, Test erreur:  0.8151575922966003, Test Précision: 52.499996185302734\n",
      " epoch: 1, Test erreur:  0.7536423802375793, Test Précision: 58.0\n",
      " epoch: 1, Test erreur:  0.7054776549339294, Test Précision: 61.66666793823242\n",
      " epoch: 1, Test erreur:  0.7074341177940369, Test Précision: 60.000003814697266\n",
      " epoch: 1, Test erreur:  0.7424691915512085, Test Précision: 58.749996185302734\n",
      " epoch: 1, Test erreur:  0.7314978241920471, Test Précision: 60.000003814697266\n",
      " epoch: 1, Test erreur:  0.7751728296279907, Test Précision: 57.57575607299805\n",
      "------------\n",
      " batch: 250/388, erreur:  1.5481761693954468, Précision: 40.0\n",
      " batch: 260/388, erreur:  1.2025001049041748, Précision: 50.0\n",
      " batch: 270/388, erreur:  0.9863350987434387, Précision: 60.000003814697266\n",
      " batch: 280/388, erreur:  0.8659384250640869, Précision: 62.5\n",
      " batch: 290/388, erreur:  0.8071612119674683, Précision: 64.0\n",
      " batch: 300/388, erreur:  0.720501720905304, Précision: 68.33333587646484\n",
      " batch: 310/388, erreur:  0.7188664078712463, Précision: 67.14285278320312\n",
      " batch: 320/388, erreur:  0.6921861171722412, Précision: 68.75\n",
      " batch: 330/388, erreur:  0.702369213104248, Précision: 67.77777862548828\n",
      " batch: 340/388, erreur:  0.7067078351974487, Précision: 66.0\n",
      " batch: 350/388, erreur:  0.7031320929527283, Précision: 65.45454406738281\n",
      " batch: 360/388, erreur:  0.6995739936828613, Précision: 65.0\n",
      " batch: 370/388, erreur:  0.7182086110115051, Précision: 63.846153259277344\n",
      " batch: 380/388, erreur:  0.7413486838340759, Précision: 61.42856979370117\n",
      " batch: 390/388, erreur:  0.750023603439331, Précision: 60.000003814697266\n",
      " batch: 400/388, erreur:  0.7539379000663757, Précision: 59.375\n",
      " batch: 410/388, erreur:  0.7446213960647583, Précision: 60.000003814697266\n",
      " batch: 420/388, erreur:  0.7418307065963745, Précision: 59.4444465637207\n",
      " batch: 430/388, erreur:  0.7305550575256348, Précision: 61.05263137817383\n",
      " batch: 440/388, erreur:  0.7279423475265503, Précision: 60.5\n",
      " batch: 450/388, erreur:  0.7323505878448486, Précision: 59.523807525634766\n",
      " batch: 460/388, erreur:  0.7247711420059204, Précision: 60.45454788208008\n",
      " batch: 470/388, erreur:  0.7312088012695312, Précision: 58.695648193359375\n",
      " batch: 480/388, erreur:  0.7264463305473328, Précision: 59.166664123535156\n",
      " batch: 490/388, erreur:  0.7251410484313965, Précision: 58.39999771118164\n",
      " epoch: 2, Test erreur:  0.8007634878158569, Test Précision: 60.000003814697266\n",
      " epoch: 2, Test erreur:  0.7194111347198486, Test Précision: 65.0\n",
      " epoch: 2, Test erreur:  0.7135562896728516, Test Précision: 63.33333206176758\n",
      " epoch: 2, Test erreur:  0.7026010155677795, Test Précision: 65.0\n",
      " epoch: 2, Test erreur:  0.6853914260864258, Test Précision: 64.0\n",
      " epoch: 2, Test erreur:  0.6673038601875305, Test Précision: 66.66667175292969\n",
      " epoch: 2, Test erreur:  0.6607203483581543, Test Précision: 67.14285278320312\n",
      " epoch: 2, Test erreur:  0.6731475591659546, Test Précision: 63.75\n",
      " epoch: 2, Test erreur:  0.6703116297721863, Test Précision: 64.44444274902344\n",
      " epoch: 2, Test erreur:  0.6853407621383667, Test Précision: 62.626258850097656\n",
      "------------\n",
      " batch: 500/388, erreur:  0.8870046734809875, Précision: 40.0\n",
      " batch: 510/388, erreur:  0.7818472981452942, Précision: 50.0\n",
      " batch: 520/388, erreur:  0.7119953036308289, Précision: 60.000003814697266\n",
      " batch: 530/388, erreur:  0.6717867851257324, Précision: 62.5\n",
      " batch: 540/388, erreur:  0.6533522605895996, Précision: 64.0\n",
      " batch: 550/388, erreur:  0.6192865371704102, Précision: 68.33333587646484\n",
      " batch: 560/388, erreur:  0.6233957409858704, Précision: 67.14285278320312\n",
      " batch: 570/388, erreur:  0.6137577891349792, Précision: 68.75\n",
      " batch: 580/388, erreur:  0.6229496002197266, Précision: 67.77777862548828\n",
      " batch: 590/388, erreur:  0.6265029907226562, Précision: 66.0\n",
      " batch: 600/388, erreur:  0.6299362778663635, Précision: 65.45454406738281\n",
      " batch: 610/388, erreur:  0.6299915909767151, Précision: 65.0\n",
      " batch: 620/388, erreur:  0.6401547193527222, Précision: 63.846153259277344\n",
      " batch: 630/388, erreur:  0.6579562425613403, Précision: 61.42856979370117\n",
      " batch: 640/388, erreur:  0.6661254167556763, Précision: 60.66666793823242\n",
      " batch: 650/388, erreur:  0.6722490191459656, Précision: 59.375\n",
      " batch: 660/388, erreur:  0.6690362095832825, Précision: 59.411766052246094\n",
      " batch: 670/388, erreur:  0.6707541942596436, Précision: 58.33333206176758\n",
      " batch: 680/388, erreur:  0.6664363741874695, Précision: 59.47368240356445\n",
      " batch: 690/388, erreur:  0.6673570275306702, Précision: 60.000003814697266\n",
      " batch: 700/388, erreur:  0.672257661819458, Précision: 59.04762268066406\n",
      " batch: 710/388, erreur:  0.6690275073051453, Précision: 60.000003814697266\n",
      " batch: 720/388, erreur:  0.6753648519515991, Précision: 59.130435943603516\n",
      " batch: 730/388, erreur:  0.6733676791191101, Précision: 58.749996185302734\n",
      " batch: 740/388, erreur:  0.6744449734687805, Précision: 57.20000457763672\n",
      " epoch: 3, Test erreur:  0.7781164050102234, Test Précision: 50.0\n",
      " epoch: 3, Test erreur:  0.7152074575424194, Test Précision: 50.0\n",
      " epoch: 3, Test erreur:  0.7086659073829651, Test Précision: 53.333335876464844\n",
      " epoch: 3, Test erreur:  0.7002547979354858, Test Précision: 55.0\n",
      " epoch: 3, Test erreur:  0.6878747940063477, Test Précision: 54.000003814697266\n",
      " epoch: 3, Test erreur:  0.6728211045265198, Test Précision: 55.0\n",
      " epoch: 3, Test erreur:  0.666944146156311, Test Précision: 58.57142639160156\n",
      " epoch: 3, Test erreur:  0.6752023696899414, Test Précision: 52.499996185302734\n",
      " epoch: 3, Test erreur:  0.6740022301673889, Test Précision: 54.44444274902344\n",
      " epoch: 3, Test erreur:  0.6857031583786011, Test Précision: 51.51515197753906\n",
      "------------\n",
      " batch: 750/388, erreur:  0.8209503293037415, Précision: 40.0\n",
      " batch: 760/388, erreur:  0.7443361282348633, Précision: 50.0\n",
      " batch: 770/388, erreur:  0.692791759967804, Précision: 60.000003814697266\n",
      " batch: 780/388, erreur:  0.6618355512619019, Précision: 62.5\n",
      " batch: 790/388, erreur:  0.6466621160507202, Précision: 64.0\n",
      " batch: 800/388, erreur:  0.6193873286247253, Précision: 68.33333587646484\n",
      " batch: 810/388, erreur:  0.6230475306510925, Précision: 67.14285278320312\n",
      " batch: 820/388, erreur:  0.6150064468383789, Précision: 68.75\n",
      " batch: 830/388, erreur:  0.6234949827194214, Précision: 67.77777862548828\n",
      " batch: 840/388, erreur:  0.6268472671508789, Précision: 66.0\n",
      " batch: 850/388, erreur:  0.6296054124832153, Précision: 65.45454406738281\n",
      " batch: 860/388, erreur:  0.6296544671058655, Précision: 65.0\n",
      " batch: 870/388, erreur:  0.6371028423309326, Précision: 63.846153259277344\n",
      " batch: 880/388, erreur:  0.6524690985679626, Précision: 61.42856979370117\n",
      " batch: 890/388, erreur:  0.6602423191070557, Précision: 59.33333206176758\n",
      " batch: 900/388, erreur:  0.6661562919616699, Précision: 58.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch: 910/388, erreur:  0.6635031700134277, Précision: 58.235294342041016\n",
      " batch: 920/388, erreur:  0.6654157042503357, Précision: 57.22222137451172\n",
      " batch: 930/388, erreur:  0.6620609760284424, Précision: 58.421051025390625\n",
      " batch: 940/388, erreur:  0.6633265614509583, Précision: 58.499996185302734\n",
      " batch: 950/388, erreur:  0.6679269671440125, Précision: 57.619049072265625\n",
      " batch: 960/388, erreur:  0.6652589440345764, Précision: 58.63636016845703\n",
      " batch: 970/388, erreur:  0.6710842847824097, Précision: 58.26087188720703\n",
      " batch: 980/388, erreur:  0.6693646311759949, Précision: 57.916664123535156\n",
      " batch: 990/388, erreur:  0.6704597473144531, Précision: 56.400001525878906\n",
      " epoch: 4, Test erreur:  0.7703854441642761, Test Précision: 40.0\n",
      " epoch: 4, Test erreur:  0.7126941680908203, Test Précision: 45.0\n",
      " epoch: 4, Test erreur:  0.706852912902832, Test Précision: 46.66666793823242\n",
      " epoch: 4, Test erreur:  0.698976993560791, Test Précision: 50.0\n",
      " epoch: 4, Test erreur:  0.6878408193588257, Test Précision: 50.0\n",
      " epoch: 4, Test erreur:  0.6741140484809875, Test Précision: 53.333335876464844\n",
      " epoch: 4, Test erreur:  0.6685055494308472, Test Précision: 55.71428680419922\n",
      " epoch: 4, Test erreur:  0.6757673025131226, Test Précision: 50.0\n",
      " epoch: 4, Test erreur:  0.6749564409255981, Test Précision: 50.0\n",
      " epoch: 4, Test erreur:  0.6854676008224487, Test Précision: 48.48484802246094\n",
      "------------\n",
      " batch: 1000/388, erreur:  0.800127387046814, Précision: 40.0\n",
      " batch: 1010/388, erreur:  0.7330437898635864, Précision: 50.0\n",
      " batch: 1020/388, erreur:  0.6873813271522522, Précision: 60.000003814697266\n",
      " batch: 1030/388, erreur:  0.6584405899047852, Précision: 62.5\n",
      " batch: 1040/388, erreur:  0.644417941570282, Précision: 64.0\n",
      " batch: 1050/388, erreur:  0.6191844344139099, Précision: 68.33333587646484\n",
      " batch: 1060/388, erreur:  0.6225767135620117, Précision: 67.14285278320312\n",
      " batch: 1070/388, erreur:  0.6150395274162292, Précision: 68.75\n",
      " batch: 1080/388, erreur:  0.6232891082763672, Précision: 67.77777862548828\n",
      " batch: 1090/388, erreur:  0.626584529876709, Précision: 66.0\n",
      " batch: 1100/388, erreur:  0.629206120967865, Précision: 65.45454406738281\n",
      " batch: 1110/388, erreur:  0.6292740702629089, Précision: 65.0\n",
      " batch: 1120/388, erreur:  0.6358017325401306, Précision: 63.846153259277344\n",
      " batch: 1130/388, erreur:  0.6504366993904114, Précision: 61.42856979370117\n",
      " batch: 1140/388, erreur:  0.6581019759178162, Précision: 59.33333206176758\n",
      " batch: 1150/388, erreur:  0.6638563871383667, Précision: 57.5\n",
      " batch: 1160/388, erreur:  0.6613420844078064, Précision: 57.64706039428711\n",
      " batch: 1170/388, erreur:  0.6633449792861938, Précision: 56.66666793823242\n",
      " batch: 1180/388, erreur:  0.6602102518081665, Précision: 57.894737243652344\n",
      " batch: 1190/388, erreur:  0.661587655544281, Précision: 57.5\n",
      " batch: 1200/388, erreur:  0.666089653968811, Précision: 56.66666793823242\n",
      " batch: 1210/388, erreur:  0.6636309027671814, Précision: 56.818180084228516\n",
      " batch: 1220/388, erreur:  0.6692930459976196, Précision: 56.52173614501953\n",
      " batch: 1230/388, erreur:  0.6676686406135559, Précision: 56.66666793823242\n",
      " batch: 1240/388, erreur:  0.6687214374542236, Précision: 55.19999694824219\n",
      " epoch: 5, Test erreur:  0.7674105167388916, Test Précision: 40.0\n",
      " epoch: 5, Test erreur:  0.7108324766159058, Test Précision: 50.0\n",
      " epoch: 5, Test erreur:  0.7051555514335632, Test Précision: 50.0\n",
      " epoch: 5, Test erreur:  0.6974257826805115, Test Précision: 52.499996185302734\n",
      " epoch: 5, Test erreur:  0.6868780851364136, Test Précision: 52.0\n",
      " epoch: 5, Test erreur:  0.6736166477203369, Test Précision: 55.0\n",
      " epoch: 5, Test erreur:  0.66824871301651, Test Précision: 57.142860412597656\n",
      " epoch: 5, Test erreur:  0.6751595735549927, Test Précision: 52.499996185302734\n",
      " epoch: 5, Test erreur:  0.6744731664657593, Test Précision: 52.22222137451172\n",
      " epoch: 5, Test erreur:  0.6846457719802856, Test Précision: 50.50504684448242\n",
      "------------\n",
      " batch: 1250/388, erreur:  0.7978466749191284, Précision: 40.0\n",
      " batch: 1260/388, erreur:  0.7315037250518799, Précision: 50.0\n",
      " batch: 1270/388, erreur:  0.6871312260627747, Précision: 60.000003814697266\n",
      " batch: 1280/388, erreur:  0.6579551696777344, Précision: 62.5\n",
      " batch: 1290/388, erreur:  0.6439215540885925, Précision: 64.0\n",
      " batch: 1300/388, erreur:  0.6187594532966614, Précision: 68.33333587646484\n",
      " batch: 1310/388, erreur:  0.6220212578773499, Précision: 67.14285278320312\n",
      " batch: 1320/388, erreur:  0.6143923997879028, Précision: 68.75\n",
      " batch: 1330/388, erreur:  0.6223896145820618, Précision: 67.77777862548828\n",
      " batch: 1340/388, erreur:  0.6255699396133423, Précision: 66.0\n",
      " batch: 1350/388, erreur:  0.6282093524932861, Précision: 65.45454406738281\n",
      " batch: 1360/388, erreur:  0.628224790096283, Précision: 65.0\n",
      " batch: 1370/388, erreur:  0.6346403956413269, Précision: 63.846153259277344\n",
      " batch: 1380/388, erreur:  0.6492558717727661, Précision: 61.42856979370117\n",
      " batch: 1390/388, erreur:  0.6568629741668701, Précision: 59.33333206176758\n",
      " batch: 1400/388, erreur:  0.6624987721443176, Précision: 57.5\n",
      " batch: 1410/388, erreur:  0.6600457429885864, Précision: 57.64706039428711\n",
      " batch: 1420/388, erreur:  0.6621120572090149, Précision: 57.22222137451172\n",
      " batch: 1430/388, erreur:  0.6589707732200623, Précision: 58.421051025390625\n",
      " batch: 1440/388, erreur:  0.6603967547416687, Précision: 58.0\n",
      " batch: 1450/388, erreur:  0.664871335029602, Précision: 57.142860412597656\n",
      " batch: 1460/388, erreur:  0.6625069975852966, Précision: 57.727272033691406\n",
      " batch: 1470/388, erreur:  0.6681427955627441, Précision: 57.39130401611328\n",
      " batch: 1480/388, erreur:  0.6665549874305725, Précision: 57.5\n",
      " batch: 1490/388, erreur:  0.6675636172294617, Précision: 56.400001525878906\n",
      " epoch: 6, Test erreur:  0.7660061717033386, Test Précision: 40.0\n",
      " epoch: 6, Test erreur:  0.7095755338668823, Test Précision: 50.0\n",
      " epoch: 6, Test erreur:  0.7036935687065125, Test Précision: 50.0\n",
      " epoch: 6, Test erreur:  0.6959248781204224, Test Précision: 52.499996185302734\n",
      " epoch: 6, Test erreur:  0.6856403350830078, Test Précision: 54.000003814697266\n",
      " epoch: 6, Test erreur:  0.6725821495056152, Test Précision: 58.33333206176758\n",
      " epoch: 6, Test erreur:  0.6673279404640198, Test Précision: 60.000003814697266\n",
      " epoch: 6, Test erreur:  0.6740991473197937, Test Précision: 55.0\n",
      " epoch: 6, Test erreur:  0.673438310623169, Test Précision: 55.55555725097656\n",
      " epoch: 6, Test erreur:  0.683593213558197, Test Précision: 53.53535461425781\n",
      "------------\n",
      " batch: 1500/388, erreur:  0.7989462614059448, Précision: 40.0\n",
      " batch: 1510/388, erreur:  0.7318946719169617, Précision: 50.0\n",
      " batch: 1520/388, erreur:  0.6873800158500671, Précision: 60.000003814697266\n",
      " batch: 1530/388, erreur:  0.6576734185218811, Précision: 62.5\n",
      " batch: 1540/388, erreur:  0.6430071592330933, Précision: 64.0\n",
      " batch: 1550/388, erreur:  0.617401123046875, Précision: 68.33333587646484\n",
      " batch: 1560/388, erreur:  0.6205782294273376, Précision: 67.14285278320312\n",
      " batch: 1570/388, erreur:  0.6128002405166626, Précision: 68.75\n",
      " batch: 1580/388, erreur:  0.6206258535385132, Précision: 67.77777862548828\n",
      " batch: 1590/388, erreur:  0.6237311959266663, Précision: 66.0\n",
      " batch: 1600/388, erreur:  0.6265259981155396, Précision: 65.45454406738281\n",
      " batch: 1610/388, erreur:  0.626481831073761, Précision: 65.0\n",
      " batch: 1620/388, erreur:  0.6328394412994385, Précision: 63.846153259277344\n",
      " batch: 1630/388, erreur:  0.6476542353630066, Précision: 61.42856979370117\n",
      " batch: 1640/388, erreur:  0.6552695035934448, Précision: 59.33333206176758\n",
      " batch: 1650/388, erreur:  0.6608396768569946, Précision: 56.875003814697266\n",
      " batch: 1660/388, erreur:  0.6584668159484863, Précision: 57.64706039428711\n",
      " batch: 1670/388, erreur:  0.6605967283248901, Précision: 56.66666793823242\n",
      " batch: 1680/388, erreur:  0.6574471592903137, Précision: 57.894737243652344\n",
      " batch: 1690/388, erreur:  0.658907413482666, Précision: 57.0\n",
      " batch: 1700/388, erreur:  0.6634019017219543, Précision: 56.19047927856445\n",
      " batch: 1710/388, erreur:  0.6611034274101257, Précision: 56.818180084228516\n",
      " batch: 1720/388, erreur:  0.6667472720146179, Précision: 56.52173614501953\n",
      " batch: 1730/388, erreur:  0.6651977896690369, Précision: 57.08333206176758\n",
      " batch: 1740/388, erreur:  0.6661369204521179, Précision: 56.0\n",
      " epoch: 7, Test erreur:  0.7644109725952148, Test Précision: 50.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: 7, Test erreur:  0.7078845500946045, Test Précision: 55.0\n",
      " epoch: 7, Test erreur:  0.7020270824432373, Test Précision: 53.333335876464844\n",
      " epoch: 7, Test erreur:  0.694237470626831, Test Précision: 57.5\n",
      " epoch: 7, Test erreur:  0.6841708421707153, Test Précision: 60.000003814697266\n",
      " epoch: 7, Test erreur:  0.671425998210907, Test Précision: 63.33333206176758\n",
      " epoch: 7, Test erreur:  0.6662107110023499, Test Précision: 64.28571319580078\n",
      " epoch: 7, Test erreur:  0.6728719472885132, Test Précision: 61.25\n",
      " epoch: 7, Test erreur:  0.6722007989883423, Test Précision: 62.222225189208984\n",
      " epoch: 7, Test erreur:  0.6822808384895325, Test Précision: 60.60606384277344\n",
      "------------\n",
      " batch: 1750/388, erreur:  0.800457775592804, Précision: 40.0\n",
      " batch: 1760/388, erreur:  0.7325446605682373, Précision: 50.0\n",
      " batch: 1770/388, erreur:  0.6880574226379395, Précision: 60.000003814697266\n",
      " batch: 1780/388, erreur:  0.6576465964317322, Précision: 62.5\n",
      " batch: 1790/388, erreur:  0.6423500776290894, Précision: 64.0\n",
      " batch: 1800/388, erreur:  0.6163578033447266, Précision: 68.33333587646484\n",
      " batch: 1810/388, erreur:  0.6194181442260742, Précision: 67.14285278320312\n",
      " batch: 1820/388, erreur:  0.6114647388458252, Précision: 68.75\n",
      " batch: 1830/388, erreur:  0.6191369891166687, Précision: 67.77777862548828\n",
      " batch: 1840/388, erreur:  0.622199296951294, Précision: 66.0\n",
      " batch: 1850/388, erreur:  0.6250851154327393, Précision: 65.45454406738281\n",
      " batch: 1860/388, erreur:  0.6249723434448242, Précision: 65.0\n",
      " batch: 1870/388, erreur:  0.6312450766563416, Précision: 63.846153259277344\n",
      " batch: 1880/388, erreur:  0.646197497844696, Précision: 61.42856979370117\n",
      " batch: 1890/388, erreur:  0.6537984013557434, Précision: 59.33333206176758\n",
      " batch: 1900/388, erreur:  0.6592268347740173, Précision: 56.875003814697266\n",
      " batch: 1910/388, erreur:  0.6569294333457947, Précision: 58.235294342041016\n",
      " batch: 1920/388, erreur:  0.6591233015060425, Précision: 56.66666793823242\n",
      " batch: 1930/388, erreur:  0.655897319316864, Précision: 57.894737243652344\n",
      " batch: 1940/388, erreur:  0.6573993563652039, Précision: 57.0\n",
      " batch: 1950/388, erreur:  0.6619552373886108, Précision: 56.19047927856445\n",
      " batch: 1960/388, erreur:  0.6597033143043518, Précision: 57.272727966308594\n",
      " batch: 1970/388, erreur:  0.6654204726219177, Précision: 56.95652389526367\n",
      " batch: 1980/388, erreur:  0.66389399766922, Précision: 57.5\n",
      " batch: 1990/388, erreur:  0.6647941470146179, Précision: 56.400001525878906\n",
      " epoch: 8, Test erreur:  0.7640835046768188, Test Précision: 50.0\n",
      " epoch: 8, Test erreur:  0.7067219018936157, Test Précision: 55.0\n",
      " epoch: 8, Test erreur:  0.700122058391571, Test Précision: 53.333335876464844\n",
      " epoch: 8, Test erreur:  0.6925762295722961, Test Précision: 57.5\n",
      " epoch: 8, Test erreur:  0.6826940774917603, Test Précision: 60.000003814697266\n",
      " epoch: 8, Test erreur:  0.6700341701507568, Test Précision: 61.66666793823242\n",
      " epoch: 8, Test erreur:  0.6650265455245972, Test Précision: 62.85714340209961\n",
      " epoch: 8, Test erreur:  0.6717339754104614, Test Précision: 61.25\n",
      " epoch: 8, Test erreur:  0.671027421951294, Test Précision: 62.222225189208984\n",
      " epoch: 8, Test erreur:  0.6812282800674438, Test Précision: 60.60606384277344\n",
      "------------\n",
      " batch: 2000/388, erreur:  0.8019577860832214, Précision: 40.0\n",
      " batch: 2010/388, erreur:  0.7325106859207153, Précision: 50.0\n",
      " batch: 2020/388, erreur:  0.6888237595558167, Précision: 60.000003814697266\n",
      " batch: 2030/388, erreur:  0.657415509223938, Précision: 62.5\n",
      " batch: 2040/388, erreur:  0.6414222717285156, Précision: 64.0\n",
      " batch: 2050/388, erreur:  0.6149458885192871, Précision: 68.33333587646484\n",
      " batch: 2060/388, erreur:  0.6179994940757751, Précision: 67.14285278320312\n",
      " batch: 2070/388, erreur:  0.6096587777137756, Précision: 68.75\n",
      " batch: 2080/388, erreur:  0.6169834136962891, Précision: 67.77777862548828\n",
      " batch: 2090/388, erreur:  0.6202558279037476, Précision: 66.0\n",
      " batch: 2100/388, erreur:  0.623145341873169, Précision: 65.45454406738281\n",
      " batch: 2110/388, erreur:  0.6229611039161682, Précision: 65.0\n",
      " batch: 2120/388, erreur:  0.629291832447052, Précision: 63.846153259277344\n",
      " batch: 2130/388, erreur:  0.6444125175476074, Précision: 61.42856979370117\n",
      " batch: 2140/388, erreur:  0.6520870923995972, Précision: 60.000003814697266\n",
      " batch: 2150/388, erreur:  0.6573601961135864, Précision: 58.125\n",
      " batch: 2160/388, erreur:  0.6551498174667358, Précision: 59.411766052246094\n",
      " batch: 2170/388, erreur:  0.657492995262146, Précision: 57.77777862548828\n",
      " batch: 2180/388, erreur:  0.6538316607475281, Précision: 59.47368240356445\n",
      " batch: 2190/388, erreur:  0.6553593873977661, Précision: 58.499996185302734\n",
      " batch: 2200/388, erreur:  0.660087525844574, Précision: 57.619049072265625\n",
      " batch: 2210/388, erreur:  0.6578384041786194, Précision: 58.63636016845703\n",
      " batch: 2220/388, erreur:  0.6637779474258423, Précision: 58.26087188720703\n",
      " batch: 2230/388, erreur:  0.6622638702392578, Précision: 58.749996185302734\n",
      " batch: 2240/388, erreur:  0.6631454229354858, Précision: 58.0\n",
      " epoch: 9, Test erreur:  0.7636922001838684, Test Précision: 50.0\n",
      " epoch: 9, Test erreur:  0.706963062286377, Test Précision: 55.0\n",
      " epoch: 9, Test erreur:  0.6997650265693665, Test Précision: 53.333335876464844\n",
      " epoch: 9, Test erreur:  0.6917514801025391, Test Précision: 57.5\n",
      " epoch: 9, Test erreur:  0.6819139719009399, Test Précision: 60.000003814697266\n",
      " epoch: 9, Test erreur:  0.6690478920936584, Test Précision: 61.66666793823242\n",
      " epoch: 9, Test erreur:  0.6635525822639465, Test Précision: 64.28571319580078\n",
      " epoch: 9, Test erreur:  0.6696877479553223, Test Précision: 62.5\n",
      " epoch: 9, Test erreur:  0.6695495843887329, Test Précision: 63.33333206176758\n",
      " epoch: 9, Test erreur:  0.680101752281189, Test Précision: 61.61616516113281\n",
      "------------\n",
      " batch: 2250/388, erreur:  0.8052647709846497, Précision: 40.0\n",
      " batch: 2260/388, erreur:  0.7335948944091797, Précision: 50.0\n",
      " batch: 2270/388, erreur:  0.6913044452667236, Précision: 60.000003814697266\n",
      " batch: 2280/388, erreur:  0.6590213179588318, Précision: 62.5\n",
      " batch: 2290/388, erreur:  0.6415873765945435, Précision: 64.0\n",
      " batch: 2300/388, erreur:  0.6142618060112, Précision: 68.33333587646484\n",
      " batch: 2310/388, erreur:  0.6171584725379944, Précision: 67.14285278320312\n",
      " batch: 2320/388, erreur:  0.6081633567810059, Précision: 68.75\n",
      " batch: 2330/388, erreur:  0.6138471961021423, Précision: 67.77777862548828\n",
      " batch: 2340/388, erreur:  0.6176335215568542, Précision: 65.0\n",
      " batch: 2350/388, erreur:  0.6207339763641357, Précision: 64.54545593261719\n",
      " batch: 2360/388, erreur:  0.6205915212631226, Précision: 64.16666412353516\n",
      " batch: 2370/388, erreur:  0.6271762847900391, Précision: 63.076927185058594\n",
      " batch: 2380/388, erreur:  0.6424079537391663, Précision: 60.71428680419922\n",
      " batch: 2390/388, erreur:  0.6500663161277771, Précision: 59.33333206176758\n",
      " batch: 2400/388, erreur:  0.6551905870437622, Précision: 58.125\n",
      " batch: 2410/388, erreur:  0.6530877947807312, Précision: 59.411766052246094\n",
      " batch: 2420/388, erreur:  0.6556399464607239, Précision: 57.77777862548828\n",
      " batch: 2430/388, erreur:  0.6514818072319031, Précision: 59.47368240356445\n",
      " batch: 2440/388, erreur:  0.6530671715736389, Précision: 58.499996185302734\n",
      " batch: 2450/388, erreur:  0.6579867601394653, Précision: 57.619049072265625\n",
      " batch: 2460/388, erreur:  0.6557888388633728, Précision: 58.63636016845703\n",
      " batch: 2470/388, erreur:  0.6616175770759583, Précision: 58.26087188720703\n",
      " batch: 2480/388, erreur:  0.6598602533340454, Précision: 59.166664123535156\n",
      " batch: 2490/388, erreur:  0.6607990264892578, Précision: 58.39999771118164\n",
      " epoch: 10, Test erreur:  0.7538130879402161, Test Précision: 50.0\n",
      " epoch: 10, Test erreur:  0.7053515911102295, Test Précision: 50.0\n",
      " epoch: 10, Test erreur:  0.6988160014152527, Test Précision: 50.0\n",
      " epoch: 10, Test erreur:  0.6908206939697266, Test Précision: 55.0\n",
      " epoch: 10, Test erreur:  0.6807694435119629, Test Précision: 58.0\n",
      " epoch: 10, Test erreur:  0.6676023006439209, Test Précision: 60.000003814697266\n",
      " epoch: 10, Test erreur:  0.6619961857795715, Test Précision: 62.85714340209961\n",
      " epoch: 10, Test erreur:  0.6673249006271362, Test Précision: 61.25\n",
      " epoch: 10, Test erreur:  0.6682388782501221, Test Précision: 61.11111068725586\n",
      " epoch: 10, Test erreur:  0.679215133190155, Test Précision: 59.5959587097168\n",
      "------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: modele\\assets\n"
     ]
    }
   ],
   "source": [
    "epoch= 10\n",
    "batch_size = 10\n",
    "b =0\n",
    "model.compile(loss=loss_object, optimizer=optimizer)\n",
    "for epoch in range(epoch):\n",
    "    \n",
    "    for notes_batch, tagets_batch in train_dataset.batch(batch_size):\n",
    "        train_step(notes_batch, tagets_batch)\n",
    "        template = '\\r batch: {}/{}, erreur:  {}, Précision: {}'\n",
    "        print(template.format(b, len(targets), train_loss.result(), train_accuracy.result()*100))\n",
    "        b+= batch_size\n",
    "        \n",
    "        \n",
    "    for notes_batch, tagets_batch in valid_dataset.batch(batch_size):\n",
    "        test_step(notes_batch, tagets_batch)\n",
    "        template = '\\r epoch: {}, Test erreur:  {}, Test Précision: {}'\n",
    "        print(template.format(epoch+1, valid_loss.result(), valid_accuracy.result()*100))\n",
    "        \n",
    "    print(\"------------\")\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    valid_loss.reset_states()\n",
    "    valid_accuracy.reset_states()\n",
    "\n",
    "model.save(\"modele\", save_format=\"tf\")\n",
    "# tf.saved_model.save(model, \"saved_model_path\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f978eac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5008455  0.49915454]] [0]\n",
      "[[[ 2.    9.5   8.25  9.5  11.25  5.75  6.5  11.   11.5  10.    4.  ]\n",
      "  [10.   10.   10.25  9.    8.   12.25 14.   14.75 15.    0.   11.5 ]\n",
      "  [ 0.    0.    0.    0.   13.5   0.    0.   13.    0.    0.    0.  ]]]\n"
     ]
    }
   ],
   "source": [
    "load_model = tf.keras.models.load_model(\"modele\")\n",
    "pred = load_model.predict(notes[366:367])\n",
    "print(pred, targets[366:367])\n",
    "print(notes[366:367])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac5f9b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Aucun(e)",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
